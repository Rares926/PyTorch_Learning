This are 2 pytorch classes 

Info

epoch= 1 forward and backward pass of all training samples
batch_size=numer of training samples in one forward and backward pass
number of iterations =number of passes, each pass using [batch_size] number of samples

e.g. 100 samples , batch_size=20 --> 100/20 = 5 iterations for 1 epoch 


If we have a dataset we can create a separate class for it by implementing the torch.utils.data.Dataset
    -this class must implement 3 functions:
        -init where we load the dataset
        -getitem which returns an object with his label from the dataset(based on an index)
        -len which returns the number of samples from the dataset aka size 